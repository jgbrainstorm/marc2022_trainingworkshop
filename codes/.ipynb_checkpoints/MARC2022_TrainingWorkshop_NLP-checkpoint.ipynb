{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARC 2022 Training Workshop on Machine Learning and NLP \n",
    "## Part II: NLP\n",
    "\n",
    "### Jiangang Hao, ETS, contact: <jhao@ets.org>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jhao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/jhao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jhao/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text preprocessing and Ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The class is over. I hopep it is intersting to you. Please let me knoww if not.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the class is over. i hopep it is intersting to you. please let me knoww if not.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to lower case\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'class', 'is', 'over', '.', 'I', 'hopep', 'it', 'is', 'intersting', 'to', 'you', '.', 'Please', 'let', 'me', 'knoww', 'if', 'not', '.']\n"
     ]
    }
   ],
   "source": [
    "# word tokenization\n",
    "word_tokens = word_tokenize(text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'hopep', 'intersting', 'please', 'let', 'knoww']\n"
     ]
    }
   ],
   "source": [
    "# remove stop words and punctuations\n",
    "stopword_list = stopwords.words('english')\n",
    "punctuation_list = list(string.punctuation)\n",
    "cleaned_text = [txt for txt in word_tokenize(text.lower()) if txt not in stopword_list+punctuation_list]\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'hope', 'interesting', 'please', 'let', 'knoww']\n"
     ]
    }
   ],
   "source": [
    "# typo correction\n",
    "spell = SpellChecker()\n",
    "corrected_text = [spell.correction(wd) for wd in cleaned_text]\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class', 'NN'),\n",
       " ('hope', 'NN'),\n",
       " ('interesting', 'VBG'),\n",
       " ('please', 'JJ'),\n",
       " ('let', 'VB'),\n",
       " ('knoww', 'VB')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part of speech tagging\n",
    "pos_tag(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class', 'class'),\n",
       " ('hope', 'hope'),\n",
       " ('interesting', 'interest'),\n",
       " ('please', 'pleas'),\n",
       " ('let', 'let'),\n",
       " ('knoww', 'knoww')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming the words\n",
    "porter = PorterStemmer()\n",
    "stem_words = [porter.stem(txt) for txt in corrected_text]\n",
    "list(zip(corrected_text,stem_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The class is over.', 'I hopep it is intersting to you.', 'Please let me knoww if not.']\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sentence_list = sent_tokenize(text)\n",
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the stop words removal and typo correction\n",
    "correct_sentence_list = []\n",
    "for sent in sentence_list:\n",
    "    correct_sentence_list.append(' '.join([spell.correction(wd) for wd in word_tokenize(sent.lower()) \\\n",
    "                                  if wd not in stopword_list+punctuation_list]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'hope interesting', 'please let knoww']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>hope</th>\n",
       "      <th>interesting</th>\n",
       "      <th>knoww</th>\n",
       "      <th>let</th>\n",
       "      <th>please</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  hope  interesting  knoww  let  please\n",
       "0      1     0            0      0    0       0\n",
       "1      0     1            1      0    0       0\n",
       "2      0     0            0      1    1       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unigram\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1)) \n",
    "X = vectorizer.fit_transform(correct_sentence_list)\n",
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = vectorizer.get_feature_names_out()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>hope</th>\n",
       "      <th>interesting</th>\n",
       "      <th>knoww</th>\n",
       "      <th>let</th>\n",
       "      <th>please</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  hope  interesting  knoww   let  please\n",
       "0    1.0  0.00         0.00   0.00  0.00    0.00\n",
       "1    0.0  0.71         0.71   0.00  0.00    0.00\n",
       "2    0.0  0.00         0.00   0.58  0.58    0.58"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-Idf transformation of unigram\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1)) \n",
    "X = vectorizer.fit_transform(correct_sentence_list)\n",
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = vectorizer.get_feature_names_out()\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class is</th>\n",
       "      <th>hopep it</th>\n",
       "      <th>if not</th>\n",
       "      <th>intersting to</th>\n",
       "      <th>is intersting</th>\n",
       "      <th>is over</th>\n",
       "      <th>it is</th>\n",
       "      <th>knoww if</th>\n",
       "      <th>let me</th>\n",
       "      <th>me knoww</th>\n",
       "      <th>please let</th>\n",
       "      <th>the class</th>\n",
       "      <th>to you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class is  hopep it  if not  intersting to  is intersting  is over  it is  \\\n",
       "0         1         0       0              0              0        1      0   \n",
       "1         0         1       0              1              1        0      1   \n",
       "2         0         0       1              0              0        0      0   \n",
       "\n",
       "   knoww if  let me  me knoww  please let  the class  to you  \n",
       "0         0       0         0           0          1       0  \n",
       "1         0       0         0           0          0       1  \n",
       "2         1       1         1           1          0       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bigram\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(sentence_list)\n",
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = vectorizer.get_feature_names_out()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Latent Semantic Analysis\n",
    "Here is a great tutorial for more details for using Gensim: <https://www.datacamp.com/tutorial/discovering-hidden-topics-python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of topics\n",
    "num_components=2 \n",
    "\n",
    "# create SVD object\n",
    "lsa = TruncatedSVD(n_components=num_components, n_iter=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit SVD model on data\n",
    "lsa.fit_transform(X)\n",
    "\n",
    "# Get Singular values and Components \n",
    "Sigma = lsa.singular_values_ \n",
    "V_transpose = lsa.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.19518474e-17, -1.03829427e-16],\n",
       "       [ 7.07106781e-01,  9.03795930e-17],\n",
       "       [ 7.07106781e-01,  3.55817821e-17],\n",
       "       [-1.21774228e-16,  5.77350269e-01],\n",
       "       [-1.21774228e-16,  5.77350269e-01],\n",
       "       [-1.21774228e-16,  5.77350269e-01]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics with their terms\n",
    "terms = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:  ['hope', 'interesting', 'class', 'knoww', 'let']\n",
      "Topic 1:  ['knoww', 'let', 'please', 'hope', 'interesting']\n"
     ]
    }
   ],
   "source": [
    "# Print the topics\n",
    "\n",
    "def print_topics(lsa_model):\n",
    "    for index, component in enumerate(lsa_model.components_):\n",
    "        zipped = zip(terms, component)\n",
    "        top_terms_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:5]\n",
    "        top_terms_list=list(dict(top_terms_key).keys())\n",
    "        print(\"Topic \"+str(index)+\": \",top_terms_list)\n",
    "print_topics(lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Neural Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word vectors (word2vec)\n",
    "import gensim.downloader as api\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "#loading the 100 dimension word vector dictionary trained on twitter data. https://nlp.stanford.edu/projects/glove/\n",
    "model = api.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38446  , -0.45507  ,  0.45351  ,  0.4301   , -0.050908 ,\n",
       "       -0.26414  ,  0.43253  , -0.3166   ,  0.32214  ,  0.0064333,\n",
       "       -0.47066  ,  0.95335  , -3.2063   ,  0.010913 , -0.27565  ,\n",
       "        1.1732   ,  0.52033  , -0.045973 ,  0.094254 , -0.53846  ,\n",
       "        0.0035668,  0.11934  , -0.17815  , -0.58093  ,  0.65081  ,\n",
       "       -0.48746  , -0.50961  ,  0.42771  , -0.30638  ,  0.32385  ,\n",
       "        0.33687  , -0.1717   , -0.39104  , -0.19038  ,  0.37016  ,\n",
       "       -0.50396  ,  0.041969 , -0.20517  ,  0.3223   ,  0.41217  ,\n",
       "       -0.42191  , -0.26359  , -0.1773   , -0.35658  ,  0.52145  ,\n",
       "        0.57282  ,  0.60204  ,  0.74369  ,  0.33377  , -0.45041  ,\n",
       "        0.015978 , -0.12575  ,  0.29786  , -0.77635  ,  0.23759  ,\n",
       "        0.63821  ,  0.63726  ,  1.0079   ,  0.13714  , -0.031928 ,\n",
       "       -0.21299  ,  0.52348  ,  0.67934  , -0.1427   , -0.64236  ,\n",
       "       -0.47996  , -0.87915  ,  0.17501  ,  0.64517  ,  0.3778   ,\n",
       "        0.53493  , -0.29723  , -0.25206  , -0.757    ,  0.33647  ,\n",
       "        0.053759 , -0.8084   ,  0.22205  ,  0.10799  , -0.68982  ,\n",
       "        1.5073   ,  0.96641  , -0.51839  ,  0.32803  ,  0.11878  ,\n",
       "       -0.72009  ,  0.23227  ,  0.098733 , -0.096396 ,  0.40295  ,\n",
       "       -0.003925 , -0.10405  , -0.15234  ,  0.17573  ,  0.29694  ,\n",
       "        0.14938  ,  0.11754  ,  0.15699  , -0.34272  ,  0.2435   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vector of the word cat\n",
    "model.get_vector('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dinosaurs', 0.7145547866821289),\n",
       " ('turtle', 0.6854123473167419),\n",
       " ('monkey', 0.6693367958068848),\n",
       " ('unicorn', 0.6604658961296082),\n",
       " ('t-rex', 0.6527642011642456),\n",
       " ('jurassic', 0.6525610089302063),\n",
       " ('penguin', 0.6506965756416321),\n",
       " ('extinct', 0.6369237303733826),\n",
       " ('pig', 0.6347753405570984),\n",
       " ('frog', 0.6319982409477234)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the most similar words as cat\n",
    "model.most_similar('dinosaur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6474888920783997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity between cat and tiger\n",
    "1-cosine(model.get_vector('cat'), model.get_vector('tiger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936834692955017"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity between cat and kitten\n",
    "1-cosine(model.get_vector('cat'), model.get_vector('kitten'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5291033983230591"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarit between cat and car\n",
    "1-cosine(model.get_vector('cat'), model.get_vector('car'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deep Learning Language Models\n",
    "<https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the blank task\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>token</th>\n",
       "      <th>token_str</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213851</td>\n",
       "      <td>15411</td>\n",
       "      <td>course</td>\n",
       "      <td>Hello I'm Jiangang, and I am running a course ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130649</td>\n",
       "      <td>18507</td>\n",
       "      <td>class</td>\n",
       "      <td>Hello I'm Jiangang, and I am running a class t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127468</td>\n",
       "      <td>1528</td>\n",
       "      <td>program</td>\n",
       "      <td>Hello I'm Jiangang, and I am running a program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093742</td>\n",
       "      <td>13452</td>\n",
       "      <td>project</td>\n",
       "      <td>Hello I'm Jiangang, and I am running a project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068059</td>\n",
       "      <td>10696</td>\n",
       "      <td>school</td>\n",
       "      <td>Hello I'm Jiangang, and I am running a school ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  token token_str  \\\n",
       "0  0.213851  15411    course   \n",
       "1  0.130649  18507     class   \n",
       "2  0.127468   1528   program   \n",
       "3  0.093742  13452   project   \n",
       "4  0.068059  10696    school   \n",
       "\n",
       "                                            sequence  \n",
       "0  Hello I'm Jiangang, and I am running a course ...  \n",
       "1  Hello I'm Jiangang, and I am running a class t...  \n",
       "2  Hello I'm Jiangang, and I am running a program...  \n",
       "3  Hello I'm Jiangang, and I am running a project...  \n",
       "4  Hello I'm Jiangang, and I am running a school ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(unmasker(\"Hello I'm Jiangang, and I am running a <mask> to teach people machine learning.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>token</th>\n",
       "      <th>token_str</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479797</td>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>It is ironic and somehow tragic that good peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.098909</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>It is ironic and somehow tragic that good peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032577</td>\n",
       "      <td>4127</td>\n",
       "      <td>good</td>\n",
       "      <td>It is ironic and somehow tragic that good peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020705</td>\n",
       "      <td>17723</td>\n",
       "      <td>happy</td>\n",
       "      <td>It is ironic and somehow tragic that good peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016820</td>\n",
       "      <td>17110</td>\n",
       "      <td>sad</td>\n",
       "      <td>It is ironic and somehow tragic that good peop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  token token_str  \\\n",
       "0  0.479797      5         .   \n",
       "1  0.098909     27       ...   \n",
       "2  0.032577   4127      good   \n",
       "3  0.020705  17723     happy   \n",
       "4  0.016820  17110       sad   \n",
       "\n",
       "                                            sequence  \n",
       "0  It is ironic and somehow tragic that good peop...  \n",
       "1  It is ironic and somehow tragic that good peop...  \n",
       "2  It is ironic and somehow tragic that good peop...  \n",
       "3  It is ironic and somehow tragic that good peop...  \n",
       "4  It is ironic and somehow tragic that good peop...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another one, A: ordinary, B: stubborn, C: skeptical, D. fascinating, E. unobtrusive\n",
    "pd.DataFrame(unmasker(\"It is ironic and somehow tragic that good people are often dull while evil people can be endlessly <mask>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence generation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import pipeline, set_seed\n",
    "#generator = pipeline('text-generation', model='gpt2')\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n",
    "set_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today, I am giving a traing workshop on machine learning and NLP. I am going to \n",
      "be working with a group from Stanford, and will be speaking to students\n",
      "over the course of the course. I am very excited and looking forward to\n",
      "working with a great group of people, and I hope to make some new\n",
      "contributions in the coming week. I would like to ask for any recommendations\n",
      "of topics that I should study if I do get this opportunity. I know that\n",
      "studying computational linguistics is a very active field right now, so I\n",
      "will\n"
     ]
    }
   ],
   "source": [
    "prompt='Today, I am giving a traing workshop on machine learning and NLP. I am going to '\n",
    "print(generator(prompt, max_length=120, num_return_sequences=1)[0].get('generated_text'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
